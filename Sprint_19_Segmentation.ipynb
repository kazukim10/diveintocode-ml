{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint セグメンテーション１"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## このSprintについて\n",
    "### Sprintの目的\n",
    "* コンピュータビジョンの代表的タスクであるセグメンテーションを学ぶ\n",
    "\n",
    "### どのように学ぶか\n",
    "公開されている実装を用いてKaggleコンペティションのデータでセグメンテーションを行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### セグメンテーション\n",
    "KaggleのTGS Salt Identification Challengeのデータセットを使用し、セグメンテーションを行います。\n",
    "\n",
    "TGS Salt Identification Challenge | Kaggle  \n",
    "https://www.kaggle.com/c/tgs-salt-identification-challenge\n",
    "\n",
    "\n",
    "セグメンテーション手法としてU-Net[1]を使います。\n",
    "\n",
    "[1]O.Ronneberger, P.Fischer, T.Brox. U-Net: Convolutional Networks for Biomedical Image Segmentation. Medical Image Computing and Computer-Assisted Intervention (MICCAI), Springer, LNCS, Vol.9351: 234–241, 2015\n",
    "\n",
    "https://arxiv.org/pdf/1505.04597.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題1】学習・推定\n",
    "以下のKeras実装を使用して学習・推定を行ってください。\n",
    "\n",
    "zhixuhao/unet: unet for image segmentation  \n",
    "https://github.com/zhixuhao/unet\n",
    "\n",
    "《GPU環境での学習》\n",
    "\n",
    "大規模なデータセット、大きなモデルになるため、GPUを使用する必要があります。\n",
    "\n",
    "《新たなデータセットの適用》\n",
    "\n",
    "公開されている実装で用意されたものとは異なるデータセットを入力するための準備が必要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your Unet with membrane data\n",
    "membrane data is in folder membrane/, it is a binary classification task.\n",
    "\n",
    "The input shape of image and mask are the same :(batch_size,rows,cols,channel = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-48efa1714f06>:22: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Found 490 images belonging to 1 classes.\n",
      "Found 490 images belonging to 1 classes.\n",
      "Epoch 1/5\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6877 - accuracy: 0.7333  \n",
      "Epoch 00001: loss improved from inf to 0.68771, saving model to unet_salt.hdf5\n",
      "10/10 [==============================] - 1741s 174s/step - loss: 0.6877 - accuracy: 0.7333\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5566 - accuracy: 0.7561  \n",
      "Epoch 00002: loss improved from 0.68771 to 0.55663, saving model to unet_salt.hdf5\n",
      "10/10 [==============================] - 1732s 173s/step - loss: 0.5566 - accuracy: 0.7561\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5820 - accuracy: 0.7604  \n",
      "Epoch 00003: loss did not improve from 0.55663\n",
      "10/10 [==============================] - 1145s 114s/step - loss: 0.5820 - accuracy: 0.7604\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5739 - accuracy: 0.7230  \n",
      "Epoch 00004: loss did not improve from 0.55663\n",
      "10/10 [==============================] - 1707s 171s/step - loss: 0.5739 - accuracy: 0.7230\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5049 - accuracy: 0.7654  \n",
      "Epoch 00005: loss improved from 0.55663 to 0.50486, saving model to unet_salt.hdf5\n",
      "10/10 [==============================] - 2112s 211s/step - loss: 0.5049 - accuracy: 0.7654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd7bf4ebbe0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                     width_shift_range=0.05,\n",
    "                     height_shift_range=0.05,\n",
    "                     shear_range=0.05,\n",
    "                     zoom_range=0.05,\n",
    "                     horizontal_flip=True,\n",
    "                     fill_mode='nearest')\n",
    "\n",
    "myGene = trainGenerator(20,\n",
    "                        'data/membrane/train',\n",
    "                        'image',\n",
    "                        'label',\n",
    "                        data_gen_args,\n",
    "                        save_to_dir = None)\n",
    "\n",
    "model = unet()\n",
    "model_checkpoint = ModelCheckpoint('unet_salt.hdf5',\n",
    "                                   monitor='loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True)\n",
    "\n",
    "model.fit_generator(myGene,\n",
    "                    steps_per_epoch=10,\n",
    "                    epochs=5,\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with npy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgs_train,imgs_mask_train = geneTrainNpy(\"data/membrane/train/aug/\",\"data/membrane/train/aug/\")\n",
    "#model.fit(imgs_train, imgs_mask_train, batch_size=2, nb_epoch=10, verbose=1,validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test your model and save predicted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 16s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/kazuki/diveintocode-ml/スプリント/unet-master/data.py:126: UserWarning: data/membrane/test/1_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/kazuki/diveintocode-ml/スプリント/unet-master/data.py:126: UserWarning: data/membrane/test/2_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/kazuki/diveintocode-ml/スプリント/unet-master/data.py:126: UserWarning: data/membrane/test/3_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/kazuki/diveintocode-ml/スプリント/unet-master/data.py:126: UserWarning: data/membrane/test/4_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/kazuki/diveintocode-ml/スプリント/unet-master/data.py:126: UserWarning: data/membrane/test/5_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/kazuki/diveintocode-ml/スプリント/unet-master/data.py:126: UserWarning: data/membrane/test/6_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/kazuki/diveintocode-ml/スプリント/unet-master/data.py:126: UserWarning: data/membrane/test/7_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/kazuki/diveintocode-ml/スプリント/unet-master/data.py:126: UserWarning: data/membrane/test/8_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/kazuki/diveintocode-ml/スプリント/unet-master/data.py:126: UserWarning: data/membrane/test/9_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "testGene = testGenerator(\"data/membrane/test\")\n",
    "model = unet()\n",
    "model.load_weights(\"unet_salt.hdf5\")\n",
    "results = model.predict_generator(testGene,10,verbose=1)\n",
    "saveResult(\"data/membrane/test\",results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題2】コードリーディング\n",
    "論文[1]に目を通した上で、上記実装のコードリーディングを行ってください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* U-Netの構成\n",
    "1. Affine layerがない\n",
    "2. downsampling(3x3conv 2回 --> ReLU --> 2x2maxpooling)を行う。feature map が2倍ずつ増える\n",
    "3. upsampling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
