{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 深層学習スクラッチ 畳み込みニューラルネットワーク２"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>目次<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#このSprintについて\" data-toc-modified-id=\"このSprintについて-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>このSprintについて</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sprintの目的\" data-toc-modified-id=\"Sprintの目的-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Sprintの目的</a></span></li><li><span><a href=\"#どのように学ぶか\" data-toc-modified-id=\"どのように学ぶか-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>どのように学ぶか</a></span></li></ul></li><li><span><a href=\"#2次元の畳み込みニューラルネットワークスクラッチ\" data-toc-modified-id=\"2次元の畳み込みニューラルネットワークスクラッチ-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>2次元の畳み込みニューラルネットワークスクラッチ</a></span><ul class=\"toc-item\"><li><span><a href=\"#データセットの用意\" data-toc-modified-id=\"データセットの用意-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>データセットの用意</a></span></li><li><span><a href=\"#【問題1】2次元畳み込み層の作成\" data-toc-modified-id=\"【問題1】2次元畳み込み層の作成-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>【問題1】2次元畳み込み層の作成</a></span></li><li><span><a href=\"#【問題2】2次元畳み込み後の出力サイズ\" data-toc-modified-id=\"【問題2】2次元畳み込み後の出力サイズ-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>【問題2】2次元畳み込み後の出力サイズ</a></span></li><li><span><a href=\"#【問題3】最大プーリング層の作成\" data-toc-modified-id=\"【問題3】最大プーリング層の作成-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>【問題3】最大プーリング層の作成</a></span></li><li><span><a href=\"#【問題4】（アドバンス課題）平均プーリングの作成\" data-toc-modified-id=\"【問題4】（アドバンス課題）平均プーリングの作成-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>【問題4】（アドバンス課題）平均プーリングの作成</a></span></li><li><span><a href=\"#【問題5】平滑化\" data-toc-modified-id=\"【問題5】平滑化-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>【問題5】平滑化</a></span></li><li><span><a href=\"#【問題6】学習と推定\" data-toc-modified-id=\"【問題6】学習と推定-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>【問題6】学習と推定</a></span></li><li><span><a href=\"#【問題7】（アドバンス課題）LeNet\" data-toc-modified-id=\"【問題7】（アドバンス課題）LeNet-2.8\"><span class=\"toc-item-num\">2.8&nbsp;&nbsp;</span>【問題7】（アドバンス課題）LeNet</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## このSprintについて\n",
    "### Sprintの目的\n",
    "* スクラッチを通してCNNの基礎を理解する\n",
    "\n",
    "### どのように学ぶか\n",
    "スクラッチで2次元用畳み込みニューラルネットワークを実装した後、学習と検証を行なっていきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2次元の畳み込みニューラルネットワークスクラッチ\n",
    "2次元に対応した畳み込みニューラルネットワーク（CNN）のクラスをスクラッチで作成していきます。  \n",
    "NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。  \n",
    "  \n",
    "プーリング層なども作成することで、CNNの基本形を完成させます。  \n",
    "クラスの名前はScratch2dCNNClassifierとしてください。\n",
    "\n",
    "### データセットの用意\n",
    "引き続きMNISTデータセットを使用します。2次元畳み込み層へは、28×28の状態で入力します。\n",
    "\n",
    "今回は白黒画像ですからチャンネルは1つしかありませんが、チャンネル方向の軸は用意しておく必要があります。\n",
    "\n",
    "(n_samples, n_channels, height, width)のNCHWまたは(n_samples, height, width, n_channels)のNHWCどちらかの形にしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インポート\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNISTデータセットのダウンロード\n",
    "from keras.datasets import mnist\n",
    "(X, y), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 28, 28)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "# データの確認\n",
    "print(X.shape) # (60000, 28, 28)\n",
    "print(X.shape) # (10000, 28, 28)\n",
    "print(X[0].dtype) # uint8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題1】2次元畳み込み層の作成\n",
    "1次元畳み込み層のクラスConv1dを発展させ、2次元畳み込み層のクラスConv2dを作成してください。\n",
    "\n",
    "フォワードプロパゲーションの数式は以下のようになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$a_{i,j,m} = \\sum_{k=0}^{K-1}\\sum_{s=0}^{F_{h}-1}\\sum_{t=0}^{F_{w}-1}x_{(i+s),(j+t),k}w_{s,t,k,m}+b_{m}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1次元畳み込み層クラス\n",
    "class SimpleConv2d():\n",
    "    \"\"\"\n",
    "    2次元畳み込み層\n",
    "    Parameters\n",
    "    ----------\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, N, C, H, W, F, FH, FW, P, S,\n",
    "                 initializer=None,optimizer=None,activation=None):\n",
    "        self.P = P\n",
    "        self.S = S\n",
    "        self.initializer = initializer\n",
    "        self.optimizer = optimizer\n",
    "        self.activation = activation\n",
    "        \n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = self.initializer.W(F,C,FH,FW)\n",
    "        self.B = self.initializer.B(F)\n",
    "        \n",
    "    def output_shape2d(IH=5,IW=5,PH=0,PW=0,FH=3,FW=3,SH=1,SW=1):\n",
    "        OH = (IH +2*PH -FH)/SH +1\n",
    "        OW = (IW +2*PW -FW)/SW +1\n",
    "        return int(OH),int(OW)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        N,C,H,W = self.X.shape\n",
    "        F,C,FH,FW = self.W.shape\n",
    "        \n",
    "        OH,OW = output_shape2d(H,W,self.P,self.P,FH,FW,self.S,self.S)\n",
    "\n",
    "        A = np.zeros([N,F,OH,OW])\n",
    "\n",
    "        self.X_pad = np.pad(X,((0,0),(0,0),(P,P),(P,P)))\n",
    "\n",
    "        # バッチ\n",
    "        for n in range(N):\n",
    "            # 出力チャンネル\n",
    "            for ch in range(F):\n",
    "                # 縦方向のスライド\n",
    "                for row in range(0,H,S):\n",
    "                    # 横方向のスライド\n",
    "                    for col in range(0,W,S):\n",
    "                        A[n,ch,row,col] = \\\n",
    "                        np.sum(self.X_pad[n,:,row:row+FH,col:col+FW]*self.W[ch,:,:,:]) +self.B[ch]\n",
    "        \n",
    "        return  self.activation.forward(A)\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        dZ = np.zeros(self.X_pad.shape)\n",
    "        self.dW = np.zeros(self.W.shape)\n",
    "        self.dB = np.zeros(self.B.shape)\n",
    "        \n",
    "        N,C,H,W = self.X.shape\n",
    "        F,C,FH,FW = self.W.shape\n",
    "        OH,OW = output_shape2d(H,W,self.P,self.P,FH,FW,self.S,self.S)\n",
    "        \n",
    "        \n",
    "        # dZ\n",
    "        # バッチ\n",
    "        for n in range(N):\n",
    "            # 出力チャンネル\n",
    "            for ch in range(F):\n",
    "                # 縦方向のスライド\n",
    "                for row in range(0,H,S):\n",
    "                    # 横方向のスライド\n",
    "                    for col in range(0,W,S):\n",
    "                        dZ[n,:,row:row+FH,col:col+FW] += dA[n,ch,row,col]*w[ch,:,:,:]\n",
    "                \n",
    "        dl_rows = range(P),range(H+P,H+2*P,1)\n",
    "        dl_cols = range(P),range(W+P,W+2*P,1)\n",
    "\n",
    "        dZ = np.delete(dZ,dl_rows,axis=2)\n",
    "        dZ = np.delete(dZ,dl_cols,axis=3)\n",
    "                \n",
    "        # dW\n",
    "        # バッチ\n",
    "        for n in range(N):\n",
    "            # 出力チャンネル\n",
    "            for ch in range(F):\n",
    "                # 縦方向のスライド\n",
    "                for row in range(OH):\n",
    "                    # 横方向のスライド\n",
    "                    for col in range(OW):\n",
    "                        self.dW[ch,:,:,:] += dA[n,ch,row,col]*X_pad[n,:,row:row+FH,col:col+FW]\n",
    "        \n",
    "        # dB\n",
    "        # 出力チャンネル\n",
    "        for ch in range(F):\n",
    "            self.dB[ch] = np.sum(dA[:,ch,:,:])\n",
    "        \n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        \n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializerConv2d:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma=0.01):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, F, C, FH, FW):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        W : 重み\n",
    "        \"\"\"\n",
    "        return self.sigma * np.random.randn(F,C,FH,FW)\n",
    "    \n",
    "    def B(self, F):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B : バイアス\n",
    "        \"\"\"\n",
    "        return np.zeros(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        layer.W -= self.lr*layer.dW\n",
    "        layer.B -= self.lr*layer.dB\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    \"\"\"\n",
    "    活性化関数 : ReLU関数\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def forward(self,A):\n",
    "        self.A = A\n",
    "        return np.maximum(self.A,0)\n",
    "    \n",
    "    def backward(self,dZ):\n",
    "        \n",
    "        return np.where(self.A>0,dZ,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題2】2次元畳み込み後の出力サイズ\n",
    "畳み込みを行うと特徴マップのサイズが変化します。  \n",
    "どのように変化するかは以下の数式から求められます。  \n",
    "この計算を行う関数を作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_shape2d(IH=5,IW=5,PH=0,PW=0,FH=3,FW=3,SH=1,SW=1):\n",
    "    OH = (IH +2*PH -FH)/SH +1\n",
    "    OW = (IW +2*PW -FW)/SW +1\n",
    "    return int(OH),int(OW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n"
     ]
    }
   ],
   "source": [
    "print(output_shape2d(IH=6,IW=6,PH=0,PW=0,FH=3,FW=3,SH=1,SW=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.shape: (5, 4, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "N,C,H,W = (5,1,28,28)\n",
    "F,C,FH,FW = (4,1,3,3)\n",
    "\n",
    "S = 1 #とりあえず固定\n",
    "P = 1\n",
    "\n",
    "OH,OW = output_shape2d(H,W,P,P,FH,FW,S,S)\n",
    "\n",
    "A = np.zeros([N,F,OH,OW])\n",
    "\n",
    "X_sample = X[0:N].reshape(N,C,H,W)\n",
    "X_pad = np.pad(X_sample,((0,0),(0,0),(P,P),(P,P)))\n",
    "w = np.ones([F,C,FH,FW])\n",
    "B = np.ones(F)\n",
    "\n",
    "# フォワード\n",
    "\n",
    "# バッチ\n",
    "for n in range(N):\n",
    "    # 出力チャンネル\n",
    "    for ch in range(F):\n",
    "        # 縦方向のスライド\n",
    "        for row in range(0,H,S):\n",
    "            # 横方向のスライド\n",
    "            for col in range(0,W,S):\n",
    "                A[n,ch,row,col] = \\\n",
    "                np.sum(X_pad[n,:,row:row+FH,col:col+FW]*w[ch,:,:,:]) +B[ch]\n",
    "                \n",
    "print('A.shape:',A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dZ.shape: (5, 1, 28, 28)\n",
      "dW.shape: (4, 1, 3, 3)\n",
      "dB.shape: (4,)\n"
     ]
    }
   ],
   "source": [
    "# バックワード\n",
    "dA = np.ones(A.shape)\n",
    "\n",
    "dZ = np.zeros(X_pad.shape)\n",
    "dW = np.zeros(w.shape)\n",
    "dB = np.zeros(B.shape)\n",
    "\n",
    "# dZ\n",
    "# バッチ\n",
    "for n in range(N):\n",
    "    # 出力チャンネル\n",
    "    for ch in range(F):\n",
    "        # 縦方向のスライド\n",
    "        for row in range(0,H,S):\n",
    "            # 横方向のスライド\n",
    "            for col in range(0,W,S):\n",
    "                dZ[n,:,row:row+FH,col:col+FW] += dA[n,ch,row,col]*w[ch,:,:,:]\n",
    "                \n",
    "dl_rows = range(P),range(H+P,H+2*P,1)\n",
    "dl_cols = range(P),range(W+P,W+2*P,1)\n",
    "\n",
    "dZ = np.delete(dZ,dl_rows,axis=2)\n",
    "dZ = np.delete(dZ,dl_cols,axis=3)\n",
    "                \n",
    "# dW\n",
    "# バッチ\n",
    "for n in range(N):\n",
    "    # 出力チャンネル\n",
    "    for ch in range(F):\n",
    "        # 縦方向のスライド\n",
    "        for row in range(OH):\n",
    "            # 横方向のスライド\n",
    "            for col in range(OW):\n",
    "                dW[ch,:,:,:] += dA[n,ch,row,col]*X_pad[n,:,row:row+FH,col:col+FW]\n",
    "                \n",
    "# dB\n",
    "# 出力チャンネル\n",
    "for ch in range(F):\n",
    "    dB[ch] = np.sum(dA[:,ch,:,:])\n",
    "                \n",
    "print('dZ.shape:',dZ.shape)\n",
    "print('dW.shape:',dW.shape)\n",
    "print('dB.shape:',dB.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】最大プーリング層の作成\n",
    "最大プーリング層のクラスMaxPool2Dを作成してください。  \n",
    "プーリング層は数式で表さない方が分かりやすい部分もありますが、数式で表すとフォワードプロパゲーションは以下のようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D:\n",
    "    def __ini__(self,PS=2):\n",
    "        self.PS = PS\n",
    "        self.PA = None\n",
    "        self.Pindex = None\n",
    "        \n",
    "    def forward(self,N,F,OH,OW):\n",
    "        # プーリング\n",
    "        self.PA = np.zeros([N,F,int(OH/PS),int(OW/PS)])\n",
    "        self.Pindex = np.zeros([N,F,int(OH/PS),int(OW/PS)])\n",
    "        \n",
    "        for n in range(N):\n",
    "            # 出力チャンネル\n",
    "            for ch in range(F):\n",
    "                # 縦方向のスライド\n",
    "                for row in range(0,OH,PS):\n",
    "                    # 横方向のスライド\n",
    "                    for col in range(0,OW,PS):\n",
    "                        self.PA[n,ch,int(row/PS),int(col/PS)] = \\\n",
    "                        np.max(A[n,ch,row:row+PS,col:col+PS])\n",
    "                        \n",
    "                        self.Pindex[n,ch,int(row/PS),int(col/PS)] = \\\n",
    "                        np.argmax(A[n,ch,row:row+PS,col:col+PS])\n",
    "                        \n",
    "        return self.PA\n",
    "    \n",
    "    def backward(self,dA):\n",
    "        dP = np.zeros(A.shape)\n",
    "        \n",
    "        for n in range(N):\n",
    "            # 出力チャンネル\n",
    "            for ch in range(F):\n",
    "                # 縦方向のスライド\n",
    "                for row in range(0,OH,PS):\n",
    "                    # 横方向のスライド\n",
    "                    for col in range(0,OW,PS):\n",
    "                        idx = int(Pindex[n,ch,int(row/PS),int(col/PS)])\n",
    "                        tmp = np.zeros((PS*PS))\n",
    "                        for i,j in enumerate(dA[n,ch,row:row+PS,col:col+PS].reshape(-1,)):\n",
    "                            if i == idx:\n",
    "                                tmp[i] = j\n",
    "                            else:\n",
    "                                tmp[i] = 0\n",
    "                        tmp = tmp.reshape(PS,PS)\n",
    "                        dP[n,ch,row:row+PS,col:col+PS] = tmp\n",
    "        \n",
    "        return dP\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PA.shape:\n",
      " (5, 4, 7, 7)\n",
      "Pindex.shape:\n",
      " 0.0\n"
     ]
    }
   ],
   "source": [
    "# プーリングのサイズ、ストライド\n",
    "PS = 4\n",
    "\n",
    "# プーリング\n",
    "PA = np.zeros([N,F,int(OH/PS),int(OW/PS)])\n",
    "Pindex = np.zeros([N,F,int(OH/PS),int(OW/PS)])\n",
    "\n",
    "# フォワード\n",
    "# バッチ\n",
    "for n in range(N):\n",
    "    # 出力チャンネル\n",
    "    for ch in range(F):\n",
    "        # 縦方向のスライド\n",
    "        for row in range(0,OH,PS):\n",
    "            # 横方向のスライド\n",
    "            for col in range(0,OW,PS):\n",
    "                PA[n,ch,int(row/PS),int(col/PS)] = np.max(A[n,ch,row:row+PS,col:col+PS])\n",
    "                Pindex[n,ch,int(row/PS),int(col/PS)] = np.argmax(A[n,ch,row:row+PS,col:col+PS])\n",
    "                \n",
    "                #print(A[n,ch,row:row+PS,col:col+PS])\n",
    "                #print(np.argmax(A[n,ch,row:row+PS,col:col+PS]))\n",
    "                      \n",
    "print('PA.shape:\\n',PA.shape)\n",
    "print('Pindex.shape:\\n',Pindex[0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dP:\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "dP = np.zeros(A.shape)\n",
    "dA = np.ones(A.shape)\n",
    "\n",
    "# バックワード\n",
    "# バッチ\n",
    "for n in range(N):\n",
    "    # 出力チャンネル\n",
    "    for ch in range(F):\n",
    "        # 縦方向のスライド\n",
    "        for row in range(0,OH,PS):\n",
    "            # 横方向のスライド\n",
    "            for col in range(0,OW,PS):\n",
    "                idx = int(Pindex[n,ch,int(row/PS),int(col/PS)])\n",
    "                tmp = np.zeros((PS*PS))\n",
    "                for i,j in enumerate(dA[n,ch,row:row+PS,col:col+PS].reshape(-1,)):\n",
    "                    if i == idx:\n",
    "                        tmp[i] = j\n",
    "                    else:\n",
    "                        tmp[i] = 0\n",
    "                tmp = tmp.reshape(PS,PS)\n",
    "                dP[n,ch,row:row+PS,col:col+PS] = tmp\n",
    "                \n",
    "print('dP:\\n',dP[0,0,0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題4】（アドバンス課題）平均プーリングの作成\n",
    "平均プーリング層のクラスAveragePool2Dを作成してください。\n",
    "\n",
    "範囲内の最大値ではなく、平均値を出力とするプーリング層です。\n",
    "\n",
    "画像認識関係では最大プーリング層が一般的で、平均プーリングはあまり使われません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題5】平滑化\n",
    "平滑化するためのFlattenクラスを作成してください。\n",
    "\n",
    "フォワードのときはチャンネル、高さ、幅の3次元を1次元にreshapeします。その値は記録しておき、バックワードのときに再びreshapeによって形を戻します。\n",
    "\n",
    "この平滑化のクラスを挟むことで出力前の全結合層に適した配列を作ることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    def __ini__(self,):\n",
    "        pass\n",
    "    def forward(self,X):\n",
    "        self.shape = X.shape\n",
    "        return X.reshape(len(X),-1)\n",
    "\n",
    "    def backward(self,X):\n",
    "        return X.reshape(self.shape)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward_shape: (20, 50)\n",
      "Backward_shape: (20, 2, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "TEST = np.zeros([20,2,5,5])\n",
    "flt = Flatten()\n",
    "flat_forward = flt.forward(TEST)\n",
    "print('Forward_shape:',flat_forward.shape)\n",
    "print('Backward_shape:',flt.backward(flat_forward).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題6】学習と推定\n",
    "作成したConv2dを使用してMNISTを学習・推定し、Accuracyを計算してください。\n",
    "\n",
    "精度は低くともまずは動くことを目指してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d = SimpleConv2d(N=5, C=1, H=28, W=28, F=4, FH=3, FW=3, P=1, S=1,\n",
    "                      initializer=SimpleInitializerConv2d(),\n",
    "                      optimizer=SGD(),\n",
    "                      activation=ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.forward(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スクラッチ　CNN\n",
    "class Scratch2dCNNClassifier():\n",
    "    \"\"\"\n",
    "    N層の畳み込みニューラルネットワーク分類器\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    self.n_epoch : エポック数\n",
    "    self.n_batch : バッチ数\n",
    "    self.verbose : 学習過程を可視化\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, NN, n_epoch=5, n_batch=1, verbose = False):\n",
    "        #　パラメータ\n",
    "        self.n_epoch = n_epoch\n",
    "        self.n_batch = n_batch\n",
    "        self.verbose = verbose\n",
    "        self.log_loss = np.zeros(self.n_epoch)\n",
    "        self.log_acc = np.zeros(self.n_epoch)\n",
    "        self.NN = NN\n",
    "        \n",
    "    def loss_function(self,y,yt):\n",
    "        delta = 1e-7\n",
    "        return -np.mean(yt*np.log(y+delta))\n",
    "    \n",
    "    def accuracy(self,Z,Y):\n",
    "        return accuracy_score(Y,Z)\n",
    "                \n",
    "    def fit(self, X, y, X_val=False, y_val=False):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        for epoch in range(self.n_epoch):\n",
    "            # ミニバッチ処理\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.n_batch)\n",
    "            \n",
    "            self.loss = 0\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                \n",
    "                # 順伝播\n",
    "                forward_data = mini_X_train\n",
    "                forward_data = conv.forward(forward_data)\n",
    "                forward_data = forward_data.reshape(self.n_batch,-1)\n",
    "                \n",
    "                for layer in range(len(self.NN)):\n",
    "                    forward_data = self.NN[layer].forward(forward_data)\n",
    "                    \n",
    "                # 予測値\n",
    "                Z = forward_data\n",
    "                \n",
    "                # 逆伝播\n",
    "                backward_data = (Z - mini_y_train)/self.n_batch\n",
    "                for layer in range(len(self.NN)-1,-1,-1):\n",
    "                    backward_data = self.NN[layer].backward(backward_data)\n",
    "                \n",
    "                conv.backward(backward_data.reshape(self.n_batch,100,782))\n",
    "                \n",
    "                # 損失関数\n",
    "                self.loss += self.loss_function(Z,mini_y_train)\n",
    "                \n",
    "            self.log_loss[epoch] = self.loss/len(get_mini_batch)\n",
    "            self.log_acc[epoch] = self.accuracy(self.predict(X),np.argmax(y,axis=1))\n",
    "            \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        y_pred = np.zeros(len(X))\n",
    "        for i,pred in enumerate(X):\n",
    "            pred_data = pred.reshape(1,-1)\n",
    "            pred_data = conv.forward(pred_data)\n",
    "            pred_data = pred_data.reshape(1,-1)\n",
    "        \n",
    "            for layer in range(len(self.NN)):\n",
    "                pred_data = self.NN[layer].forward(pred_data)\n",
    "                y_pred[i] = np.argmax(pred_data,axis=1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題7】（アドバンス課題）LeNet\n",
    "CNNで画像認識を行う際は、フィルタサイズや層の数などを１から考えるのではなく、有名な構造を利用することが一般的です。現在では実用的に使われることはありませんが、歴史的に重要なのは1998年の LeNet です。この構造を再現してMNISTに対して動かし、Accuracyを計算してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "目次",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
